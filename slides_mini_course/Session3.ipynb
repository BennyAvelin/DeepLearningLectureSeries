{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Introduction to deep learning\n",
    "Benny Avelin\n",
    "<p><a href=\"https://commons.wikimedia.org/wiki/File:Colored_neural_network.svg#/media/File:Colored_neural_network.svg\">\n",
    "<center><img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/4/46/Colored_neural_network.svg/1200px-Colored_neural_network.svg.png\" width=500px alt=\"Colored neural network.svg\">\n",
    "        </a>\n",
    "        </center>\n",
    "        <br>\n",
    "        <font size=\"1\">By <a href=\"//commons.wikimedia.org/wiki/User_talk:Glosser.ca\" title=\"User talk:Glosser.ca\">Glosser.ca</a> - <span class=\"int-own-work\" lang=\"en\">Own work</span>, Derivative of <a href=\"//commons.wikimedia.org/wiki/File:Artificial_neural_network.svg\" title=\"File:Artificial neural network.svg\">File:Artificial neural network.svg</a>, <a href=\"https://creativecommons.org/licenses/by-sa/3.0\" title=\"Creative Commons Attribution-Share Alike 3.0\">CC BY-SA 3.0</a>, <a href=\"https://commons.wikimedia.org/w/index.php?curid=24913461\">Link</a>\n",
    "    </p>\n",
    "    </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Definitions (Skip)\n",
    "$\\newcommand{\\R}{\\mathbb{R}}$\n",
    "$\\newcommand{\\E}{\\mathbb{E}}$\n",
    "$\\newcommand{\\H}{\\mathcal{H}}$\n",
    "$\\newcommand{\\VCdim}{\\text{VC-dim}(\\H)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Overview (session 3)\n",
    "\n",
    "* Quick recap\n",
    "* Gradient descent algorithm\n",
    "* Stochastic gradient descent\n",
    "* Can we model gradient descent?\n",
    "* What is the connection to PDE?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Previously\n",
    "## Risk & hypothesis\n",
    "* Let us consider data $(x,y) \\sim \\mu$, where $x \\in \\R^n$ and $y \\in \\R^m$. \n",
    "* A hypothesis is a function $h: \\R^n \\to \\R^m$\n",
    "* A loss-function $L:\\R^m \\times \\R^m \\to \\R_+$\n",
    "$$R(h) = \\E_{\\mu}\\left[L(h(x),y)\\right], \\quad \\textbf{Risk}$$\n",
    "* Given a data-set $D = \\{(x_1,y_1), \\ldots (x_N,y_N)\\}$ which are sampled i.i.d. from $\\mu$ we also define\n",
    "$$R_{emp,D} (h) = \\frac{1}{N}\\sum_{i=1}^N \\left[L(h(x_i),y_i)\\right], \\quad \\textbf{Empirical Risk}$$\n",
    "* Call a set of hypothesis $\\H$, the hypothesis space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Previously\n",
    "## Goal\n",
    "\n",
    "* Find $h^\\ast \\in \\H$ such that\n",
    "$$R(h^\\ast) = \\min_{\\H} R(h), \\quad \\textbf{Risk minimization}$$\n",
    "* We dont have access to $\\mu$ but we have access to a given data-set $D$, we could try to find $h_D^\\ast \\in \\H$ such that\n",
    "$$R_{emp,D}(h_D^\\ast) = \\min_{\\H} R_{emp,D}(h)$$\n",
    "* We cannot find $h_D^\\ast$ in general. Instead we try to find $h \\in \\H$ such that $R_{emp,D}(h)$ is as small as possible\n",
    "$$R_{emp,D}(h_D^\\ast) \\leq R_{emp,D}(h), \\quad \\textbf{Empirical Risk Min}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Why gradient descent\n",
    "\n",
    "* Consider a parametrization of the hypothesis space $\\H$ by parameters in $\\R^d$, we identify $h \\in \\H$ with a point in $\\R^d$.\n",
    "* If $R_{emp,D}(h)$ is continuously differentiable w.r.t. to $h \\in \\R^d$ then we can perform gradient descent.\n",
    "* We now have a way to perform **Empirical Risk Minimization**.\n",
    "* In many texts $R_{emp,D}$ is simply called the loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Gradient descent algorithm\n",
    "\n",
    "1. Initialize a first guess for $h \\in \\R^d$, call that $h_0$.\n",
    "2. Choose learning rate $\\alpha > 0$.\n",
    "2. For each $i = 1,\\ldots$:\n",
    "    1. $h_i = h_{i-1} - \\alpha \\left ( \\nabla_h R_{emp,D} \\right )(h_{i-1})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Gradient descent algorithm (continuous version)\n",
    "\n",
    "$$\\frac{\\partial}{\\partial t} h(t) = - \\nabla_h R_{emp,D}(h(t)), \\quad h(0)=h_0$$\n",
    "\n",
    "* This is a standard gradient flow equation, and the rate of decrease is given by\n",
    "\n",
    "$$\\partial_t R_{emp,D}(h(t)) = \\partial_t h \\nabla_h R_{emp,D}(h(t)) = - \\alpha\\|\\nabla_h R_{emp,D}(h(t))\\|^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* If $R_{emp,D}$ is convex and $C^2$ then $\\|\\nabla_h R_{emp,D}\\| \\approx |h-h_D^\\ast|$\n",
    "\n",
    "$$\\partial_t (h-h_D)^2 = 2 \\partial_t h (h-h_D) = - \\nabla_h R_{emp,D}(h(t)) (h(t)-h_D) \\approx -|h-h_D^\\ast|^2$$\n",
    "\n",
    "$$(h(t)-h_D)^2 \\approx C e^{-c_1 t}$$\n",
    "\n",
    "* This is a linear convergence rate (very good)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Computational expense\n",
    "\n",
    "Remember\n",
    "$$R_{emp,D} (h) = \\frac{1}{N}\\sum_{i=1}^N \\left[L(h(x_i),y_i)\\right], \\quad \\textbf{Empirical Risk}$$\n",
    "\n",
    "$$\\nabla_h R_{emp,D} (h) = \\frac{1}{N}\\sum_{i=1}^N \\left[ \\nabla_h L(h(x_i),y_i)\\right]$$\n",
    "\n",
    "thus to compute the full gradient we require $N$ times the computational cost + $N$ times the memory cost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Stochastic gradient descent (SGD)\n",
    "\n",
    "1. Initialize a first guess for $h \\in \\R^d$, call that $h_0$.\n",
    "2. For each $i = 1,\\ldots$:\n",
    "    1. Split $D$ into the disjoint union $\\{D_{j}, j = 1,\\ldots, m_b\\}$ randomly, with all of the same size.\n",
    "    2. $h^0_{i-1} = h_{i-1}$\n",
    "    3. For each $D_j \\in \\{D_{j},j=1,\\ldots,m_b\\}$:\n",
    "        1. $h^j_{i-1} = h^{j-1}_{i-1} - \\alpha \\left ( \\nabla_h R_{emp,D_j} \\right )(h^{j-1}_{i-1})$\n",
    "    4. Set $h_i = h^{m_b}_{i-1}$.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Stochastic minimization (Robbins & Monro, 1951)\n",
    "\n",
    "Consider the extreme case when $|D_j| = 1$, then we can think of our problem as stochastic optimization of a sum of functions.\n",
    "* Consider $f(W) = \\frac{1}{d} \\sum_{i=1}^d f_i(W)$\n",
    "* Random selection $i_k \\in \\{1,2,\\ldots,n\\}$, equal probability.\n",
    "* Update rule: $$W_{k+1} = W_k - \\alpha_k \\nabla_W f_{i_k}(W_{k})$$\n",
    "\n",
    "Assume $f \\in C^2$, bounded from below and satisfy,\n",
    "$$f(W_2) \\leq f(W_1) + \\nabla f(W_1)^T(W_2-W_1) + \\frac{L}{2} \\|W_2-W_1\\|^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Since we dont know that the algorithm is doing a descent each time, we need to use the \"worst case\" bound.**\n",
    "Applying the convexity together with the update rule we get\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    f(W_{k+1})  &\\leq f(W_{k}) + \\nabla f(W_{k})^T(W_{k+1}-W_{k}) + \\frac{L}{2} \\|W_{k+1}-W_k\\|^2 \\\\\n",
    "                &\\leq f(W_{k}) - \\alpha_k \\nabla f(W_{k})^T \\nabla f_{i_k}(W_{k}) + \\frac{L \\alpha_k^2}{2} \\|\\nabla f_{i_k}(W_{k})\\|^2\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "now taking the expectation on both sides we obtain\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\E[f(W_{k+1})]\n",
    "                &\\leq \\E[f(W_{k})] + \\left ( \\frac{L \\alpha_k^2}{2} - \\alpha_k \\right ) \\E[\\|\\nabla f(W_{k})\\|^2]\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "reshuffling and summing over $k$ gives us,\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\min_{k \\leq m} \\E[\\|\\nabla f(W_{k})\\|^2] \\sum_{k=1}^m \\alpha_k\n",
    "                &\\leq \\sum_{k=1}^m \\left (\\E[f(W_{k})] - \\E[f(W_{k+1})] \\right ) + \\sum_{k=1}^m \\frac{L \\alpha_k^2}{2}\\sup_k \\E[\\|\\nabla f(W_{k})\\|^2]\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "thus we get\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\min_{k \\leq m} \\E[\\|\\nabla f(W_{k})\\|^2] \n",
    "                &\\leq \\frac{\\E[f(W_{1})] - \\E[f(W_{m})]}{\\sum_{k=1}^m \\alpha_k} + \\frac{L}{2}\\frac{\\sum_{k=1}^m \\alpha_k^2}{\\sum_{k=1}^m \\alpha_k}\\sup_k \\E[\\|\\nabla f(W_{k})\\|^2]\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Now for convergence to a local minima we need to have $\\frac{\\sum_{k=1}^m \\alpha_k^2}{\\sum_{k=1}^m \\alpha_k} \\to 0$ as $m \\to \\infty$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Convergence rates\n",
    "* $\\alpha_k = 1/k$ gives $O(1/\\log(k))$\n",
    "* $\\alpha_k = 1/\\sqrt(k)$ gives $O(1/\\sqrt{k})$\n",
    "* If there was no noise we can use constant step-size and get $O(1/k)$.\n",
    "\n",
    "For a given error bound $\\epsilon > 0$ we need he following number of iterations \n",
    "\n",
    "|  Steps needed    | Deterministic        | Stochastic         |\n",
    "|------------------|----------------------|--------------------|\n",
    "| Convex           |$O(1/\\epsilon)$       |$O(1/\\epsilon^2)$   |\n",
    "| Strongly Convex  |$O(\\log(1/\\epsilon))$ |$O(1/\\epsilon)$     |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Open problems\n",
    "\n",
    "* The observed convergence rate is faster for SGD than for GD, is this a consequence of the overparametrization?\n",
    "* The SGD seems to regularize the problem and gives better estimators.\n",
    "    * Q: Overparametrization + SGD => regularization + improved convergence\n",
    "* Ma, Bassily, Belkin, 2018 used an interpolation assumption to prove that SGD improves convergence rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# SGD Continuous model (Li, Tai, Weinan, 2017)\n",
    "\n",
    "* We assumed that the *mini-batch* gradient was an unbiased estimator of the *full* gradient.\n",
    "* We can use the following model to describe the mini-batch stochastic gradient descent\n",
    "\n",
    "$$X_{k+1} = X_k - \\alpha \\nabla f_{i_k}(X_{k}) + \\sqrt{\\alpha} V_k$$\n",
    "$$V_k = \\sqrt{\\alpha}( \\nabla f(x_k) - \\nabla f_{i_k}(x_k))$$\n",
    "\n",
    "* We have $\\E[V_k|x_k] = 0$, and covariance matrix $\\Sigma(x) = \\frac{1}{m}\\sum_{i=1}^m (\\nabla f(x) - \\nabla f_{i}(x))(\\nabla f(x) - \\nabla f_{i}(x))^T$\n",
    "\n",
    "* Under some assumptions: $$dX_t = -\\nabla f(X_t) dt + \\sqrt{\\alpha \\Sigma(X_t)} dW_t$$ is an order $1$ weak approximation of the SGD.\n",
    "* $$dX_t = -\\nabla \\left (f(X_t) + \\frac{\\alpha}{4} |\\nabla f(X_t)|^2 \\right ) dt + \\sqrt{\\alpha \\Sigma(X_t)} dW_t$$ is an order $2$ weak approximation of the SGD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Fokker-Planck\n",
    "\n",
    "$$dX_t = -\\nabla f(X_t) dt + \\sqrt{\\alpha \\Sigma(X_t)} dW_t$$\n",
    "\n",
    "has a corresponding density $\\rho(x,t)$ (for $X_t$) that satisfies the Fokker-Planck equation\n",
    "\n",
    "$$\\frac{\\partial \\rho}{\\partial t} = \\nabla \\cdot \\left (\\nabla f \\rho + \\frac{\\alpha}{2}\\nabla \\cdot (\\Sigma \\rho) \\right )$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* If $\\Sigma = c I$ and $\\nabla f(x) = x$ then the SDE becomes the **Ornstein-Uhlenbeck** equation and the Fokker-Planck equation is the canonical Fokker-Planck. That is, we are running SGD on $\\|x\\|^2$.\n",
    "* If $\\Sigma = \\sigma I$ and $f$ is convex then the SDE becomes the **stochastic gradient flow** equation on the potential $f$. The corresponding Fokker planck equation.\n",
    "\n",
    "$$\n",
    "    \\frac{\\partial \\rho}{\\partial t} = \\nabla \\cdot \\left (\\nabla f \\rho + \\frac{\\sigma \\alpha}{2}\\nabla \\rho \\right )\n",
    "$$\n",
    "\n",
    "Has the following stationary solution $$\\rho = e^{-\\frac{2}{\\sigma \\alpha} f}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Gradient flow\n",
    "* Consider the transformation\n",
    "$$\\rho_1 = e^{\\frac{2}{\\sigma \\alpha} f } \\rho,$$ \n",
    "* It satisifes\n",
    "$$\\nabla \\rho_1 = \\frac{2}{\\sigma \\alpha} \\nabla f e^{f} \\rho + e^{f} \\nabla \\rho$$\n",
    "* Plugging it into the Fokker-Planck equation gives\n",
    "$$\n",
    "    e^{-\\frac{2}{\\sigma \\alpha} f } \\frac{\\partial \\rho_1}{\\partial t} = \\nabla \\cdot \\left ( \\frac{\\sigma \\alpha}{2} e^{-\\frac{2}{\\sigma \\alpha} f } \\nabla \\rho_1 \\right )\n",
    "$$\n",
    "\n",
    "* Multiply by a compactly supported test function $\\phi \\in C_0^\\infty$, no time dependence, then for $d \\mu = e^{-\\frac{2}{\\sigma \\alpha} f} dx$\n",
    "\n",
    "$$\n",
    "    \\int \\frac{\\partial \\rho_1}{\\partial t} \\phi d \\mu = \\int \\nabla \\cdot \\left ( \\frac{\\sigma \\alpha}{2} e^{-\\frac{2}{\\sigma \\alpha} f } \\nabla \\rho_1 \\right ) \\phi dx\n",
    "$$\n",
    "\n",
    "* We can perform the integration by parts on the right hand side and get\n",
    "\n",
    "$$\n",
    "    \\int \\frac{\\partial \\rho_1}{\\partial t} \\phi d \\mu = - \\int \\frac{\\sigma \\alpha}{2} \\nabla \\rho_1 \\cdot \\nabla \\phi d \\mu\n",
    "$$\n",
    "\n",
    "Rescaling the time variable leads to a heat equation w.r.t. the measure $d \\mu$\n",
    "\n",
    "$$\n",
    "    \\int \\frac{\\partial \\rho_1}{\\partial t} \\phi d \\mu = - \\int \\nabla \\rho_1 \\cdot \\nabla \\phi d \\mu\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Conclusion \n",
    "Our stochastic gradient flow on $f$ gives rise to a gradient flow of the Dirichlet energy\n",
    "\n",
    "$$\n",
    "    E(\\rho) = \\frac{1}{2} \\int |\\nabla \\rho|^2 d\\mu\n",
    "$$\n",
    "\n",
    "in $L^2_\\mu$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Logarithmic Sobolev Inequality\n",
    "\n",
    "$$\n",
    "    \\int \\frac{\\partial \\rho_1}{\\partial t} \\phi d \\mu = - \\int \\nabla \\rho_1 \\cdot \\nabla \\phi d \\mu\n",
    "$$\n",
    "\n",
    "* The above heat equation has nice properties if the measure $d\\mu = e^{-f} dx$ is nice.\n",
    "* (Gross, 1975) Hypercontractivity of the equation <=> Log Sobolev of the measure $\\mu$.\n",
    "\n",
    "**Hypercontractivity** means that the equation contracts on $L^p_\\mu$, i.e. if the solution is in $L^p_\\mu$ for some time $t_p > 0$ then for any $q > p$ we can find a time $t_q > t_p$ such that the solution is in $L^q_\\mu$.\n",
    "* Why the name hypercontractivity? The solution operator defines a semigroup on $L^2_\\mu$, contraction is that norms decrease with $t$, hypercontractive is that the integrability is increased but also the norm is decreased."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Logarithmic Sobolev Inequality\n",
    "\n",
    "$$\n",
    "    \\int f^2 \\log |f| d\\mu \\leq \\int |\\nabla f|^2 d\\mu + \\|f\\|^2_{L^2_\\mu} \\log \\|f\\|_{L^2_\\mu}\n",
    "$$\n",
    "\n",
    "* \"Dimensionally independent\" estimate. Can be formulated in infinite dimensions.\n",
    "* There is a rich history of study on the HC and LS, see the *survey of surveys* by Gross (2006).\n",
    "* The Gaussian form of the log-Sobolev is used in Perelmans proof of the Poincar√© conjecture.\n",
    "* Gaussian Log-sobolev is a consequence of Gaussian Isoperimetric inequality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Next session\n",
    "\n",
    "* Understanding the SGD (Stochastic Gradient Descent) and its connection to PDEs."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
